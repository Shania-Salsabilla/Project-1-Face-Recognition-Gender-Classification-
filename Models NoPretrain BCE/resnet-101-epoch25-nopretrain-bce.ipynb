{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8667070,"sourceType":"datasetVersion","datasetId":5193796},{"sourceId":8725832,"sourceType":"datasetVersion","datasetId":5221372},{"sourceId":66977,"sourceType":"modelInstanceVersion","modelInstanceId":55852}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Library:","metadata":{}},{"cell_type":"code","source":"import os # untuk berinteraksi dengan sistem operasi, seperti untuk mengakses file dan direktori\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split # untuk membagi dataset menjadi subset training dan testing\nimport torch # Library utama PyTorch untuk komputasi tensor dan deep learning\nfrom torch.utils.data import Dataset, DataLoader # Kelas untuk memanipulasi dataset dan membuat batch data untuk training\nfrom torchvision import transforms # Modul untuk melakukan transformasi pada gambar seperti augmentasi data\nimport torch.nn as nn # Modul yang berisi berbagai komponen neural network seperti lapisan (layers), fungsi aktivasi, dll\nimport torch.optim as optim # Modul untuk algoritma optimasi, seperti SGD, Adam, dll\nimport torchvision.models as models\nimport time # Library untuk mengukur waktu eksekusi kode\nfrom torch.autograd import Variable # Kelas yang membungkus tensor untuk melacak sejarah operasi dan menghitung gradient\nfrom PIL import Image # Library untuk membuka, memanipulasi, dan menyimpan gambar\nfrom sklearn.metrics import classification_report, confusion_matrix # Fungsi untuk menghitung dan menampilkan laporan klasifikasi dan confusion matrix\nimport cv2 # Library OpenCV untuk manipulasi gambar dan video\nfrom torchvision.io import read_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation:","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/celeba/CelebA' # Menyimpan path ke direktori dataset CelebA","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(data_path) # Mengambil daftar semua file dan folder dalam direktori yang ditentukan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_list = os.listdir(data_path +'/Images') # Mengambil daftar semua file dalam subdirektori Images dari data_path\nimages_list = [i for i in images_list if len(i) < 11] # Because there are Duplicate Images 'XXXXXX(1).jpg'\nimages_list.sort()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Keterangan Kode:**\n\n- images_list = [i for i in images_list if len(i) < 11]: Membuat daftar baru images_list yang hanya berisi nama file gambar dengan panjang kurang dari 11 karakter. Hal ini dilakukan untuk menghapus gambar duplikat yang memiliki format nama 'XXXXXX(1).jpg'.\n- images_list.sort(): Mengurutkan daftar gambar images_list secara alfabetis","metadata":{}},{"cell_type":"code","source":"data = pd.DataFrame(pd.read_csv(data_path+'/list_attribute.txt', sep = '\\s+', header = 0))#, index_col = 0))\ndata = data[['file_name', 'Male']]\nnew_data =  data[data['file_name'].isin(images_list)] # filter the data with available images only (5000 images)\nnew_data = new_data.replace(-1, 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = new_data['Male']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data_male = new_data[new_data['Male'] == 1]\nnew_data_female = new_data[new_data['Male'] == 0]\nnew_data_male = new_data_male.sample(frac = 1, random_state = 42)\nnew_data_female = new_data_female.sample(frac = 1, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.concat([new_data_male[:1500], new_data_female[:1500]], axis = 0)\ntest_data = pd.concat([new_data_male[1500:], new_data_female[1500:]], axis = 0)\ntrain_data.sort_index(inplace = True)\ntest_data.sort_index(inplace = True)\ndel new_data_male\ndel new_data_female","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = train_data['Male']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing:","metadata":{}},{"cell_type":"code","source":"class GenderDataset(Dataset):\n    def __init__(self, data, image_folder_path, transform=None):\n        self.data = data\n        self.image_folder_path = image_folder_path\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path = os.path.join(self.image_folder_path, self.data.iloc[idx, 0])\n        image = Image.open(image_path).convert('RGB')\n        gender = self.data.iloc[idx, 1]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, torch.tensor(gender, dtype = torch.long)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the Transformations:\ntransforms = {\n    'train': transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.Resize(256),\n        transforms.RandomRotation(45),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = GenderDataset(train_data, image_folder_path = os.path.join(data_path, \"Images\"), transform = transforms['train'])\ntrain_loader = DataLoader(train_set, batch_size = 32, shuffle = True, num_workers = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set = GenderDataset(test_data, os.path.join(data_path, \"Images\"), transform = transforms['test'])\ntest_loader = DataLoader(test_set, batch_size = 32, shuffle = False, num_workers = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloaders = {'train': train_loader, 'test': test_loader}\ndataset_sizes = {'train': len(train_set), 'test': len(test_set)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Architecture:","metadata":{}},{"cell_type":"code","source":"# ResNet\nmodel = models.resnet101()\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the Optimizer:\noptimizer = optim.Adam(model.parameters(), lr = 0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the Loss Function:\ncriterion = nn.BCEWithLogitsLoss()  # More stable than BCELoss for binary classification","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the Model to GPU if Available:\nuse_gpu = torch.cuda.is_available()\nif use_gpu:\n    model = model.to('cuda')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling:","metadata":{}},{"cell_type":"code","source":"def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu = torch.cuda.is_available(), num_epochs = 50):\n    since = time.time()\n\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a Training and Validation Phase:\n        for phase in ['train', 'test']:\n            if phase == 'train':\n                model.train(True)  # Set model to Training Mode\n            else:\n                model.train(False)  # Set model to Evaluate Mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate Over Data:\n            for data in dataloaders[phase]:\n                # Get the Inputs:\n                inputs, labels = data\n\n                # Wrap them in Variable:\n                if use_gpu:\n                    inputs = Variable(inputs.cuda())\n                    labels = Variable(labels.cuda())\n                else:\n                    inputs, labels = Variable(inputs), Variable(labels)\n\n                # Zero the Parameter Gradients:\n                optimizer.zero_grad()\n\n                # Forward:\n                outputs = model(inputs)\n                outputs = outputs.squeeze()\n                loss = criterion(outputs, labels.float())\n                \n\n                # Backward + Optimize Only if in Training Phase:\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                # Statistics:\n                running_loss += loss.item() * inputs.size(0)\n                preds = (torch.sigmoid(outputs) > 0.5).float()\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # Deep Copy the Model:\n            if phase == 'test' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = model.state_dict()\n                state = {'model':model.state_dict(),'optim':optimizer.state_dict()}\n                torch.save(state,'/kaggle/working/model_best.pth')\n                \n            if phase == 'test':\n                last_acc = epoch_acc\n                last_model_wts = model.state_dict()\n                state = {'model':model.state_dict(),'optim':optimizer.state_dict()}\n                torch.save(state,'/kaggle/working/model_last.pth')\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best Test Acc: {:4f}'.format(best_acc))\n\n    # Load Best Model Weights:\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_gpu = torch.cuda.is_available()\n\nif use_gpu:\n  model = model.to(\"cuda\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu, 25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation:","metadata":{}},{"cell_type":"code","source":"# # For if loading weights onto a model, otherwise keep commented\n# model.load_state_dict(torch.load('/kaggle/working/model_best.pth')['model'])\n# if torch.cuda.is_available():\n#   model = model.to(\"cuda\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = torch.empty((0)).cuda()\ny_pred = torch.empty((0)).cuda()\nfor data in dataloaders['test']: \n      inputs, labels = data\n      #print(labels)\n      if torch.cuda.is_available():\n          inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n      else:\n          inputs, labels = Variable(inputs), Variable(labels)\n      outputs = model(inputs)\n      preds = (torch.sigmoid(outputs).squeeze() > 0.5).float()\n      y_true = torch.cat((y_true, labels.data), -1)\n      y_pred = torch.cat((y_pred, preds), -1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true_np = y_true.detach().cpu().numpy()\ny_pred_np = y_pred.detach().cpu().numpy()\nprint(classification_report(y_true_np, y_pred_np, digits = 4))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation","metadata":{}},{"cell_type":"code","source":"model = models.resnet101()\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_state_dict(torch.load('/kaggle/input/resnet18_genderclassification/pytorch/best/1/BestModel_ResNet18_NoPretrain_BCEwLog_epoch25.pth')['model'])\nmodel.load_state_dict(torch.load('/kaggle/working/model_best.pth')['model'])\nif torch.cuda.is_available():\n  model = model.to(\"cuda\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\nval_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_images_list = os.listdir('/kaggle/input/celeba/validation_images')\nval_images_list.sort()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_images_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inf_time_start = time.time()\nval_pred = torch.empty((0)).cuda()\nfor i in val_images_list:\n    image_path = os.path.join('/kaggle/input/celeba/validation_images', i)\n    image = Image.open(image_path).convert('RGB')\n    inputs = val_transforms(image)\n    inputs = Variable(inputs.cuda())\n    inputs = inputs.unsqueeze(0)\n    outputs = model(inputs)\n      #print(outputs)\n    preds = (torch.sigmoid(outputs).squeeze() > 0.5).float()\n    val_pred = torch.cat((val_pred, preds.reshape(1)), -1)\nprint('prediction time for each image is {} s'.format((time.time()-inf_time_start)/len(val_images_list)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}