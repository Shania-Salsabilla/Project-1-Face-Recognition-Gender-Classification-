{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os # untuk berinteraksi dengan sistem operasi, seperti untuk mengakses file dan direktori\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split # untuk membagi dataset menjadi subset training dan testing\nimport torch # Library utama PyTorch untuk komputasi tensor dan deep learning\nfrom torch.utils.data import Dataset, DataLoader # Kelas untuk memanipulasi dataset dan membuat batch data untuk training\nfrom torchvision import transforms # Modul untuk melakukan transformasi pada gambar seperti augmentasi data\nimport torch.nn as nn # Modul yang berisi berbagai komponen neural network seperti lapisan (layers), fungsi aktivasi, dll\nimport torch.optim as optim # Modul untuk algoritma optimasi, seperti SGD, Adam, dll\n# from torchvision.models import resnet50 # Model pre-trained ResNet-50 yang bisa digunakan untuk tugas klasifikasi gambar\nimport torchvision.models as models\nimport time # Library untuk mengukur waktu eksekusi kode\nfrom torch.autograd import Variable # Kelas yang membungkus tensor untuk melacak sejarah operasi dan menghitung gradient\nfrom PIL import Image # Library untuk membuka, memanipulasi, dan menyimpan gambar\nfrom sklearn.metrics import classification_report, confusion_matrix # Fungsi untuk menghitung dan menampilkan laporan klasifikasi dan confusion matrix\nimport cv2 # Library OpenCV untuk manipulasi gambar dan video\nfrom torchvision.io import read_image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = '/kaggle/input/celeb-a/Dataset' # Menyimpan path ke direktori dataset CelebA","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(data_path) # Mengambil daftar semua file dan folder dalam direktori yang ditentukan","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_list = os.listdir(data_path +'/Images') # Mengambil daftar semua file dalam subdirektori Images dari data_path\nimages_list = [i for i in images_list if len(i) < 11] # Because there are Duplicate Images 'XXXXXX(1).jpg'\nimages_list.sort()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(pd.read_csv(data_path+'/list_attribute.txt', sep = '\\s+', header = 0))#, index_col = 0))\ndata = data[['file_name', 'Male']]\nnew_data =  data[data['file_name'].isin(images_list)] # filter the data with available images only (5000 images)\nnew_data = new_data.replace(-1, 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = new_data['Male']);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data_male = new_data[new_data['Male'] == 1]\nnew_data_female = new_data[new_data['Male'] == 0]\nnew_data_male = new_data_male.sample(frac = 1, random_state = 42)\nnew_data_female = new_data_female.sample(frac = 1, random_state = 42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.concat([new_data_male[:1500], new_data_female[:1500]], axis = 0)\ntest_data = pd.concat([new_data_male[1500:], new_data_female[1500:]], axis = 0)\ntrain_data.sort_index(inplace = True)\ntest_data.sort_index(inplace = True)\ndel new_data_male\ndel new_data_female","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GenderDataset(Dataset):\n    def __init__(self, data, image_folder_path, transform=None):\n        self.data = data\n        self.image_folder_path = image_folder_path\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path = os.path.join(self.image_folder_path, self.data.iloc[idx, 0])\n        \n        # Load Image and Convert to RGB:\n#         try:\n#             image = Image.open(image_path).convert('RGB')\n#         except Exception as e:\n#             print(f\"Error loading image {image_path}: {e}\")\n#             return None, None\n        image = Image.open(image_path).convert('RGB')\n        gender = self.data.iloc[idx, 1]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, torch.tensor(gender, dtype = torch.long)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the Transformations:\ntransforms = {\n    'train': transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.Resize(256),\n        transforms.RandomRotation(45),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = GenderDataset(train_data, image_folder_path = os.path.join(data_path, \"Images\"), transform = transforms['train'])\ntrain_loader = DataLoader(train_set, batch_size = 32, shuffle = True, num_workers = 2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set = GenderDataset(test_data, os.path.join(data_path, \"Images\"), transform = transforms['test'])\ntest_loader = DataLoader(test_set, batch_size = 32, shuffle = False, num_workers = 2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloaders = {'train': train_loader, 'test': test_loader}\ndataset_sizes = {'train': len(train_set), 'test': len(test_set)}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Architecture","metadata":{}},{"cell_type":"code","source":"# VGG\nmodel = models.vgg16()\nmodel.classifier[6] = nn.Linear(4096, 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the Optimizer:\noptimizer = optim.Adam(model.parameters(), lr = 0.0001)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the Loss Function:\ncriterion = nn.CrossEntropyLoss()  # More stable than BCELoss for binary classification","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the Model to GPU if Available:\nuse_gpu = torch.cuda.is_available()\nif use_gpu:\n    model = model.to('cuda')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\ndef train_model_vgg(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu, epochs=25): \n\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for i, data in enumerate(dataloaders['train'], 0):\n            # Get the inputs\n            inputs, labels = data\n            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n\n            # Zero the parameter gradients\n            optimizer.zero_grad()\n\n            # Forward + backward + optimize\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # Print statistics\n            running_loss += loss.item()\n            if i % 100 == 99:\n                print('[%d, %5d] loss: %.3f' %\n                      (epoch + 1, i + 1, running_loss / 100))\n                running_loss = 0.0\n\n        # Test the model\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for data in dataloaders['test'] :\n                images, labels = data\n                images, labels = images.to('cuda'), labels.to('cuda')\n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        print('Accuracy of the network on the test images: %d %%' % (\n            100 * correct / total))\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best Test Acc: {:4f}'.format(best_acc))\n\n    print('Finished Training')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_gpu = torch.cuda.is_available()\n\nif use_gpu:\n  model = model.to(\"cuda\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu, 25)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"# For if loading weights onto a model, otherwise keep commented\nmodel.load_state_dict(torch.load('/kaggle/working/model_last.pth')['model'])\nif torch.cuda.is_available():\n  model = model.to(\"cuda\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = torch.empty((0)).cuda()\ny_pred = torch.empty((0)).cuda()\nfor data in dataloaders['test']: \n      inputs, labels = data\n      #print(labels)\n      if torch.cuda.is_available():\n          inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n      else:\n          inputs, labels = Variable(inputs), Variable(labels)\n      #print(labels)\n      #_, lab = torch.max(labels.data, 1)\n      outputs = model(inputs)\n      #print(outputs)\n      preds = (torch.sigmoid(outputs).squeeze() > 0.5).float()\n      y_true = torch.cat((y_true, labels.data), -1)\n      y_pred = torch.cat((y_pred, preds), -1)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true_np = y_true.detach().cpu().numpy()\ny_pred_np = y_pred.detach().cpu().numpy()\nprint(classification_report(y_true_np, y_pred_np, digits = 4))","metadata":{},"execution_count":null,"outputs":[]}]}