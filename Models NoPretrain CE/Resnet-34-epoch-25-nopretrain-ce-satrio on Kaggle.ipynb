{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os # untuk berinteraksi dengan sistem operasi, seperti untuk mengakses file dan direktori\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split # untuk membagi dataset menjadi subset training dan testing\nimport torch # Library utama PyTorch untuk komputasi tensor dan deep learning\nfrom torch.utils.data import Dataset, DataLoader # Kelas untuk memanipulasi dataset dan membuat batch data untuk training\nfrom torchvision import transforms # Modul untuk melakukan transformasi pada gambar seperti augmentasi data\nimport torch.nn as nn # Modul yang berisi berbagai komponen neural network seperti lapisan (layers), fungsi aktivasi, dll\nimport torch.optim as optim # Modul untuk algoritma optimasi, seperti SGD, Adam, dll\n# from torchvision.models import resnet50 # Model pre-trained ResNet-50 yang bisa digunakan untuk tugas klasifikasi gambar\nimport torchvision.models as models\nimport time # Library untuk mengukur waktu eksekusi kode\nfrom torch.autograd import Variable # Kelas yang membungkus tensor untuk melacak sejarah operasi dan menghitung gradient\nfrom PIL import Image # Library untuk membuka, memanipulasi, dan menyimpan gambar\nfrom sklearn.metrics import classification_report, confusion_matrix # Fungsi untuk menghitung dan menampilkan laporan klasifikasi dan confusion matrix\nimport cv2 # Library OpenCV untuk manipulasi gambar dan video\nfrom torchvision.io import read_image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = '/kaggle/input/celeb-a/Dataset' # Menyimpan path ke direktori dataset CelebA","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(data_path) # Mengambil daftar semua file dan folder dalam direktori yang ditentukan","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_list = os.listdir(data_path +'/Images') # Mengambil daftar semua file dalam subdirektori Images dari data_path\nimages_list = [i for i in images_list if len(i) < 11] # Because there are Duplicate Images 'XXXXXX(1).jpg'\nimages_list.sort()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(pd.read_csv(data_path+'/list_attribute.txt', sep = '\\s+', header = 0))#, index_col = 0))\ndata = data[['file_name', 'Male']]\nnew_data =  data[data['file_name'].isin(images_list)] # filter the data with available images only (5000 images)\nnew_data = new_data.replace(-1, 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = new_data['Male']);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data_male = new_data[new_data['Male'] == 1]\nnew_data_female = new_data[new_data['Male'] == 0]\nnew_data_male = new_data_male.sample(frac = 1, random_state = 42)\nnew_data_female = new_data_female.sample(frac = 1, random_state = 42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.concat([new_data_male[:1500], new_data_female[:1500]], axis = 0)\ntest_data = pd.concat([new_data_male[1500:], new_data_female[1500:]], axis = 0)\ntrain_data.sort_index(inplace = True)\ntest_data.sort_index(inplace = True)\ndel new_data_male\ndel new_data_female","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GenderDataset(Dataset):\n    def __init__(self, data, image_folder_path, transform=None):\n        self.data = data\n        self.image_folder_path = image_folder_path\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path = os.path.join(self.image_folder_path, self.data.iloc[idx, 0])\n        \n        # Load Image and Convert to RGB:\n#         try:\n#             image = Image.open(image_path).convert('RGB')\n#         except Exception as e:\n#             print(f\"Error loading image {image_path}: {e}\")\n#             return None, None\n        image = Image.open(image_path).convert('RGB')\n        gender = self.data.iloc[idx, 1]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, torch.tensor(gender, dtype = torch.long)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the Transformations:\ntransforms = {\n    'train': transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.Resize(256),\n        transforms.RandomRotation(45),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = GenderDataset(train_data, image_folder_path = os.path.join(data_path, \"Images\"), transform = transforms['train'])\ntrain_loader = DataLoader(train_set, batch_size = 32, shuffle = True, num_workers = 2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set = GenderDataset(test_data, os.path.join(data_path, \"Images\"), transform = transforms['test'])\ntest_loader = DataLoader(test_set, batch_size = 32, shuffle = False, num_workers = 2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloaders = {'train': train_loader, 'test': test_loader}\ndataset_sizes = {'train': len(train_set), 'test': len(test_set)}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Architecture","metadata":{}},{"cell_type":"code","source":"# ResNet\nmodel = models.resnet34()\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the Optimizer:\noptimizer = optim.Adam(model.parameters(), lr = 0.0001)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the Loss Function:\ncriterion = nn.CrossEntropyLoss()  # More stable than BCELoss for binary classification","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the Model to GPU if Available:\nuse_gpu = torch.cuda.is_available()\nif use_gpu:\n    model = model.to('cuda')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu = torch.cuda.is_available(), num_epochs = 50):\n    since = time.time()\n\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a Training and Validation Phase:\n        for phase in ['train', 'test']:\n            if phase == 'train':\n                model.train(True)  # Set model to Training Mode\n            else:\n                model.train(False)  # Set model to Evaluate Mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate Over Data:\n            for data in dataloaders[phase]:\n                # Get the Inputs:\n                inputs, labels = data\n\n                # Wrap them in Variable:\n                if use_gpu:\n                    inputs = Variable(inputs.cuda())\n                    labels = Variable(labels.cuda())\n                else:\n                    inputs, labels = Variable(inputs), Variable(labels)\n\n                # Zero the Parameter Gradients:\n                optimizer.zero_grad()\n\n                # Forward:\n                outputs = model(inputs)\n                outputs = outputs.squeeze()\n                loss = criterion(outputs, labels.float())\n\n                # Backward + Optimize Only if in Training Phase:\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                # Statistics:\n                running_loss += loss.item() * inputs.size(0)\n                preds = (torch.sigmoid(outputs) > 0.5).float()\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # Deep Copy the Model:\n            if phase == 'test' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = model.state_dict()\n                state = {'model':model.state_dict(),'optim':optimizer.state_dict()}\n                torch.save(state,'/kaggle/working/model_best.pth')\n                \n            if phase == 'test':\n                last_acc = epoch_acc\n                last_model_wts = model.state_dict()\n                state = {'model':model.state_dict(),'optim':optimizer.state_dict()}\n                torch.save(state,'/kaggle/working/model_last.pth')\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best Test Acc: {:4f}'.format(best_acc))\n\n    # Load Best Model Weights:\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_gpu = torch.cuda.is_available()\n\nif use_gpu:\n  model = model.to(\"cuda\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu, 25)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"# For if loading weights onto a model, otherwise keep commented\nmodel.load_state_dict(torch.load('/kaggle/working/model_last.pth')['model'])\nif torch.cuda.is_available():\n  model = model.to(\"cuda\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = torch.empty((0)).cuda()\ny_pred = torch.empty((0)).cuda()\nfor data in dataloaders['test']: \n      inputs, labels = data\n      #print(labels)\n      if torch.cuda.is_available():\n          inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n      else:\n          inputs, labels = Variable(inputs), Variable(labels)\n      #print(labels)\n      #_, lab = torch.max(labels.data, 1)\n      outputs = model(inputs)\n      #print(outputs)\n      preds = (torch.sigmoid(outputs).squeeze() > 0.5).float()\n      y_true = torch.cat((y_true, labels.data), -1)\n      y_pred = torch.cat((y_pred, preds), -1)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true_np = y_true.detach().cpu().numpy()\ny_pred_np = y_pred.detach().cpu().numpy()\nprint(classification_report(y_true_np, y_pred_np, digits = 4))","metadata":{},"execution_count":null,"outputs":[]}]}